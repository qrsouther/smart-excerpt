# Hypercritical Codebase Review - Findings

## Stage 1: Foundation & Architecture Review

### Phase 1.1: Documentation & Architecture Comprehension

**Files Reviewed:**
- `README.md`
- `TERMINOLOGY.md`
- `NAMING_CONVENTIONS.md`
- `src/index.js`
- `src/storage.js`

---

#### Finding 1.1.1: Terminology Inconsistency Between Documentation and Code

**Priority:** High
**Category:** Documentation
**Stage:** 1
**Phase:** 1.1
**File:** README.md, TERMINOLOGY.md, src/index.js

**Issue:** Documentation uses "Blueprint Standard" and "Embed" terminology, but code uses legacy "excerpt" and "include" terminology throughout. This creates cognitive dissonance when reading code after documentation.

**Current Code:**
- README.md refers to "Source" and "Embed" macros
- TERMINOLOGY.md maps user-facing terms to internal code terms
- `src/index.js` uses resolver names like `saveExcerpt`, `getExcerpt`, `saveVariableValues` (not `saveSource`, `saveEmbed`)

**Problem:**
- Developer must constantly translate between user-facing terminology and code terminology
- New developers reading code will be confused by "excerpt" when documentation says "Blueprint Standard"
- Code comments may use either terminology inconsistently
- Makes codebase harder to understand for new contributors

**Suggested Fix:**
1. Add JSDoc comments to all resolver functions mapping user-facing terms to code terms
2. Add a glossary at the top of `src/index.js` explaining the terminology mapping
3. Consider adding aliases in resolver definitions (e.g., `resolver.define('saveSource', saveExcerptResolver)` for backward compatibility)

**Rationale:**
- Reduces cognitive load when switching between documentation and code
- Makes onboarding easier for new developers
- Maintains backward compatibility while improving clarity

**Effort Estimate:** Small

---

#### Finding 1.1.2: Missing Architecture Diagram in README

**Priority:** Medium
**Category:** Documentation
**Stage:** 1
**Phase:** 1.1
**File:** README.md

**Issue:** README describes a "four-layer architecture" (UI Layer, Bridge Layer, Storage Layer, API Layer) but provides no visual diagram. Text description is dense and hard to parse.

**Current Code:**
```markdown
## ðŸ—ï¸ System Architecture

### Project Structure
[Text description of structure]

### Data Flow
[Text description of flows]

**Architecture Pattern:**
The Blueprint App uses a four-layer architecture...
```

**Problem:**
- Visual learners struggle to understand the architecture from text alone
- No clear diagram showing how data flows between layers
- Missing component interaction diagram
- Hard to see the big picture at a glance

**Suggested Fix:**
1. Add an ASCII art or Mermaid diagram showing the four-layer architecture
2. Add a sequence diagram showing data flow for a typical operation (e.g., "User saves Embed")
3. Add a component interaction diagram showing how UI â†’ Bridge â†’ Storage â†’ API interact

**Rationale:**
- Visual diagrams are faster to understand than prose
- Helps new developers build mental model quickly
- Makes architecture review easier

**Effort Estimate:** Small

---

#### Finding 1.1.3: Entry Point (`src/index.js`) Lacks Module Organization Documentation

**Priority:** Medium
**Category:** Documentation
**Stage:** 1
**Phase:** 1.1
**File:** src/index.js

**Issue:** `src/index.js` is 949 lines with 80+ resolver definitions but has no header documentation explaining the module organization, resolver grouping, or why resolvers are organized this way.

**Current Code:**
```javascript
import Resolver from '@forge/resolver';
// ... 40+ imports ...
const resolver = new Resolver();
// ... 80+ resolver.define() calls ...
export const handler = resolver.getDefinitions();
```

**Problem:**
- No explanation of why resolvers are grouped by phase (Phase 2, Phase 3, etc.)
- No documentation of which resolvers are one-time use vs. production
- No clear separation between production resolvers and migration/diagnostic resolvers
- Hard to understand the module's purpose without reading all 949 lines

**Suggested Fix:**
1. Add comprehensive JSDoc header explaining:
   - Purpose of this module (resolver registration hub)
   - Resolver organization strategy (by domain/phase)
   - Which resolvers are production vs. one-time use
   - How to add a new resolver
2. Add section comments grouping resolvers by domain:
   ```javascript
   // ============================================================================
   // CORE RESOLVERS - Production use
   // ============================================================================
   
   // ============================================================================
   // MIGRATION RESOLVERS - One-time use, delete after migration
   // ============================================================================
   ```

**Rationale:**
- Makes the entry point self-documenting
- Helps developers understand the codebase structure
- Makes it easier to identify which resolvers are safe to remove

**Effort Estimate:** Small

---

#### Finding 1.1.4: `src/storage.js` Contains Unused/Incomplete Implementation

**Priority:** High
**Category:** Code Smell
**Stage:** 1
**Phase:** 1.1
**File:** src/storage.js

**Issue:** `src/storage.js` contains utility functions (`saveExcerpt`, `getExcerpt`, `saveInclude`, etc.) that appear to be unused. The actual storage operations are performed directly in resolver files using `storage` from `@forge/api`.

**Current Code:**
```javascript
// src/storage.js
export async function saveExcerpt(excerptData) { ... }
export async function getExcerpt(excerptId) { ... }
export async function saveInclude(includeData) { ... }
// ... more functions ...
```

**Problem:**
- These functions are defined but never imported or used in `src/index.js` or resolver files
- Creates confusion: are these the "official" storage utilities or dead code?
- If they're meant to be used, why aren't they?
- If they're dead code, they should be removed to reduce maintenance burden

**Suggested Fix:**
1. Search codebase for imports of `src/storage.js` functions
2. If unused, remove the file or mark it as deprecated
3. If intended for use, refactor resolvers to use these utilities instead of direct `storage.set()` calls
4. Add JSDoc explaining the intended usage pattern

**Rationale:**
- Dead code increases maintenance burden
- Unclear whether this is the "right way" to do storage operations
- If these utilities provide value (caching, validation), they should be used consistently

**Effort Estimate:** Medium (requires codebase-wide search and refactoring if functions are to be used)

---

#### Finding 1.1.5: Missing Data Flow Documentation for Critical Operations

**Priority:** Medium
**Category:** Documentation
**Stage:** 1
**Phase:** 1.1
**File:** README.md

**Issue:** README describes "Data Flow" but only covers high-level flows. Missing detailed flows for critical operations like staleness detection, orphan detection, and version restoration.

**Current Code:**
```markdown
**Staleness Detection:**
1. Embed stores `syncedContentHash`...
2. On render â†’ Compare Source's current `contentHash`...
3. If different â†’ Show [Update Available banner]...
```

**Problem:**
- Staleness detection flow is described but doesn't explain:
  - When exactly the hash is calculated
  - What happens if hash calculation fails
  - How the UI polls for updates
  - What the "2-3 second delay" means in practice
- Orphan detection flow is mentioned but not detailed
- Version restoration flow is not documented in README

**Suggested Fix:**
1. Add detailed sequence diagrams for:
   - Staleness detection (with timing, error handling)
   - Orphan detection (with false positive prevention)
   - Version restoration (with backup creation)
2. Document edge cases and error scenarios
3. Add troubleshooting guide for common issues

**Rationale:**
- Critical operations need detailed documentation
- Helps developers understand system behavior
- Makes debugging easier

**Effort Estimate:** Medium

---

#### Finding 1.1.6: TERMINOLOGY.md File Mapping is Incomplete

**Priority:** Low
**Category:** Documentation
**Stage:** 1
**Phase:** 1.1
**File:** TERMINOLOGY.md

**Issue:** TERMINOLOGY.md maps some user-facing terms to code terms, but the mapping is incomplete. Many resolver functions and storage keys are not documented.

**Current Code:**
```markdown
| User-Facing Action | Resolver Function | Purpose |
|-------------------|-------------------|---------|
| Create/Edit Blueprint Standard | `saveExcerpt(req)` | Create or update a Blueprint Standard |
```

**Problem:**
- Only covers a subset of resolvers (excerpt and include operations)
- Missing mappings for:
  - Verification resolvers (`checkAllSources`, `checkAllIncludes`)
  - Version resolvers (`getVersionHistory`, `restoreFromVersion`)
  - Redline resolvers (`getRedlineQueue`, `setRedlineStatus`)
  - Storage export/import resolvers
- Storage key patterns are documented but not comprehensive

**Suggested Fix:**
1. Complete the resolver function mapping table with all resolvers
2. Add storage key pattern documentation for all key types
3. Add a "Quick Reference" section with common mappings

**Rationale:**
- Incomplete documentation is worse than no documentation (creates false confidence)
- Developers will need to search code to find unmapped terms
- Complete mapping makes onboarding faster

**Effort Estimate:** Small

---

### Phase 1.2: Core Infrastructure

**Files Reviewed:**
- `src/index.js` (resolver registration, module structure)
- `src/storage.js` (storage API abstraction)
- `src/utils/storage-validator.js` (validation layer)
- `src/utils/version-manager.js` (versioning system)

---

#### Finding 1.2.1: `src/storage.js` Functions Not Used Anywhere

**Priority:** High
**Category:** Code Smell / Dead Code
**Stage:** 1
**Phase:** 1.2
**File:** src/storage.js

**Issue:** All functions in `src/storage.js` appear to be unused. Resolvers use `storage` from `@forge/api` directly instead of these abstraction functions.

**Current Code:**
```javascript
// src/storage.js
export async function saveExcerpt(excerptData) { ... }
export async function getExcerpt(excerptId) { ... }
export async function saveInclude(includeData) { ... }
```

**Problem:**
- Dead code increases maintenance burden
- Creates confusion about the "right way" to do storage operations
- If these functions provide value (caching, validation), they should be used
- If not needed, they should be removed

**Suggested Fix:**
1. Search entire codebase for imports from `src/storage.js`
2. If unused, delete the file
3. If intended for use, refactor resolvers to use these utilities
4. Document the decision in a comment or README

**Rationale:**
- Dead code is technical debt
- Unclear purpose creates confusion
- Either use it or remove it

**Effort Estimate:** Small (if removing) / Large (if refactoring to use)

---

#### Finding 1.2.2: Storage Validator Has Comprehensive Validation But Inconsistent Usage

**Priority:** Medium
**Category:** Architecture / Consistency
**Stage:** 1
**Phase:** 1.2
**File:** src/utils/storage-validator.js

**Issue:** `storage-validator.js` provides comprehensive validation functions (`validateExcerptData`, `validateMacroVarsData`, `validateAdfStructure`) and a safe wrapper (`safeStorageSet`), but it's unclear if these are used consistently across all storage writes.

**Current Code:**
```javascript
// storage-validator.js provides:
export function validateExcerptData(excerpt) { ... }
export function safeStorageSet(storage, key, data, validator) { ... }
```

**Problem:**
- If validators exist, they should be used for ALL storage writes to prevent data corruption
- If they're not used consistently, some storage writes may bypass validation
- No way to verify that all resolvers use validation without code review

**Suggested Fix:**
1. Search codebase for all `storage.set()` calls
2. Verify that critical writes use `safeStorageSet()` or manual validation
3. Add ESLint rule or pre-commit hook to enforce validation usage
4. Document which storage keys require validation

**Rationale:**
- Validation is only effective if used consistently
- Inconsistent validation creates security/data integrity risks
- Automated enforcement prevents human error

**Effort Estimate:** Medium (requires codebase audit and potentially tooling)

---

#### Finding 1.2.3: Version Manager Has Two Different Content Hash Systems

**Priority:** High
**Category:** Clarity / Documentation
**Stage:** 1
**Phase:** 1.2
**File:** src/utils/version-manager.js:88-112

**Issue:** The codebase has TWO different `contentHash` systems with different purposes, but this is only documented in a code comment. This is confusing and error-prone.

**Current Code:**
```javascript
/**
 * NOTE: This is DISTINCT from excerpt.contentHash (calculated by hash-utils.js).
 * There are TWO contentHash properties in this codebase with different purposes:
 *
 * 1. Source contentHash (hash-utils.js - WHITELIST approach):
 *    - Purpose: Staleness detection...
 * 2. Version contentHash (THIS function - BLACKLIST approach):
 *    - Purpose: Version deduplication...
 */
```

**Problem:**
- Two hash systems with same name but different purposes is confusing
- Easy to mix them up when reading code
- Documentation is buried in code comments, not in README
- No type safety or naming distinction to prevent misuse

**Suggested Fix:**
1. Rename one of the hash properties to be more descriptive:
   - `contentHash` â†’ `stalenessHash` (for Sources)
   - `contentHash` â†’ `versionHash` (for version snapshots)
2. Update all references throughout codebase
3. Document both systems in README with clear distinction
4. Add JSDoc to both hash calculation functions explaining the difference

**Rationale:**
- Same name for different concepts is a code smell
- Renaming makes intent clear
- Documentation in README is more discoverable than code comments

**Effort Estimate:** Large (requires refactoring across codebase)

---

#### Finding 1.2.4: Version Manager Pruning Logic Has Potential Race Condition

**Priority:** Medium
**Category:** Architecture / Concurrency
**Stage:** 1
**Phase:** 1.2
**File:** src/utils/version-manager.js:558-585

**Issue:** `pruneExpiredVersionsIfNeeded()` checks `last-prune-time` and prunes if >24 hours, but there's no locking mechanism. If multiple resolver calls happen simultaneously, multiple prune operations could run concurrently.

**Current Code:**
```javascript
async function pruneExpiredVersionsIfNeeded(storageInstance) {
  const lastPruneTime = await storageInstance.get('last-prune-time');
  // ... check time ...
  if (timeSinceLastPrune > PRUNE_INTERVAL_MS) {
    await pruneExpiredVersions(storageInstance); // Could run multiple times
  }
}
```

**Problem:**
- No mutex/lock to prevent concurrent pruning
- Multiple concurrent prune operations could:
  - Waste resources (redundant work)
  - Cause storage contention
  - Create inconsistent state if pruning fails partway through

**Suggested Fix:**
1. Add a distributed lock using storage (e.g., `prune-lock` key with TTL)
2. Check lock before pruning, set lock during prune, release after
3. Handle lock acquisition failure gracefully (skip pruning if another process is doing it)
4. Add logging when pruning is skipped due to lock

**Rationale:**
- Prevents redundant work
- Reduces storage contention
- Makes pruning more efficient

**Effort Estimate:** Small

---

#### Finding 1.2.5: Storage Validator ADF Validation May Be Too Strict

**Priority:** Low
**Category:** Edge Case Handling
**Stage:** 1
**Phase:** 1.2
**File:** src/utils/storage-validator.js:267-341

**Issue:** `validateAdfStructure()` rejects ADF documents with empty content arrays, but empty documents might be valid in some contexts (e.g., newly created Source with no content yet).

**Current Code:**
```javascript
if (!Array.isArray(adf.content)) {
  errors.push('ADF root must have content array');
} else if (adf.content.length === 0) {
  errors.push('ADF content array is empty (document has no content)');
}
```

**Problem:**
- Empty ADF documents might be valid during creation
- Validation might be too strict for edge cases
- Could prevent legitimate operations (e.g., creating a Source template with no content)

**Suggested Fix:**
1. Make empty content array a warning, not an error (or configurable)
2. Document when empty ADF is acceptable
3. Add context parameter to validator to allow empty content in specific scenarios
4. Or remove this check if empty documents are valid

**Rationale:**
- Overly strict validation can block legitimate use cases
- Need to balance data integrity with flexibility
- Should be configurable based on context

**Effort Estimate:** Small

---

## Summary Statistics - Stage 1

**Files Reviewed:** 5
**Findings:** 10
**Critical:** 0
**High:** 3
**Medium:** 5
**Low:** 2

**Documentation Coverage:** ~70% (good coverage but some gaps)
**Architecture Clarity:** Good (four-layer model is clear, but needs visual diagrams)
**Code Organization:** Good (modular structure, but entry point needs documentation)

---

## Stage 4: Utilities & Helpers Review

### Phase 4.3: Infrastructure Utilities - Console Flooding

**Files Reviewed:**
- `src/utils/forge-logger.js`
- `src/utils/logger.js`
- `src/utils/performance-logger.js`
- `src/workers/helpers/page-scanner.js`
- `src/resolvers/excerpt-resolvers.js`
- `src/EmbedContainer.jsx`

---

#### Finding 4.3.1: Extensive Logging in Orphan Detection Will Flood Console

**Priority:** Critical
**Category:** Performance / Console Flooding
**Stage:** 4
**Phase:** 4.3
**File:** src/workers/helpers/page-scanner.js:56-138

**Issue:** `checkMacroExistsInADF()` logs extensively for EVERY macro search, including logging every extension node found. On pages with 50+ Embeds, this will generate hundreds of log lines per page check.

**Current Code:**
```javascript
export function checkMacroExistsInADF(node, targetLocalId, depth = 0) {
  if (depth === 0) {
    console.log(`[CHECK-MACRO] ðŸ” Searching for localId: ${targetLocalId}`);
  }
  
  if (node.type === 'extension') {
    // Log EVERY extension we find for debugging
    console.log(`[CHECK-MACRO] Found extension at depth ${depth}:`, {
      extensionType: node.attrs?.extensionType,
      extensionKey: node.attrs?.extensionKey,
      localId: node.attrs?.localId,
      // ... full object logged
    });
  }
  
  // ... more logging ...
  
  if (depth === 0) {
    console.log(`[CHECK-MACRO] âŒ Search complete - localId ${targetLocalId} NOT found in ADF`);
    console.log(`[CHECK-MACRO] âš ï¸ WARNING: About to mark as orphaned - THIS MAY BE A FALSE POSITIVE!`);
  }
}
```

**Problem:**
- Logs fire for EVERY macro search (one per Embed on page)
- Logs EVERY extension node found during recursive search
- On a page with 50 Embeds, this could generate 500+ log lines
- During "Check All Embeds" operation, this could generate thousands of log lines
- Makes debugging impossible due to console flood
- Performance impact from string serialization of large objects

**Suggested Fix:**
1. Remove or gate all logging behind a debug flag (e.g., `DEBUG_ORPHAN_DETECTION`)
2. Only log at root level (depth === 0) and only on failure
3. Use structured logger with rate limiting instead of console.log
4. Log summary statistics instead of per-extension details
5. Consider using `logger.verification()` from `logger.js` with rate limiting

**Rationale:**
- Debugging logs should not flood production console
- Rate limiting prevents console spam
- Summary logs are more useful than per-node logs

**Effort Estimate:** Small

---

#### Finding 4.3.2: 949 Console Statements Across 49 Files - No Centralized Control

**Priority:** Critical
**Category:** Console Flooding
**Stage:** 4
**Phase:** 4.3
**File:** Codebase-wide

**Issue:** Codebase has 949 `console.log/warn/error` statements across 49 files. Many are in components that render multiple times (Embeds, Sources), causing exponential log multiplication.

**Current Code:**
- Found 949 console statements across 49 files
- `src/resolvers/excerpt-resolvers.js` has 28 console.log statements (many DEBUG logs)
- `src/EmbedContainer.jsx` has 7 console statements (could fire per-Embed)
- `src/workers/helpers/page-scanner.js` has 9 console.log statements (fires per-macro search)

**Problem:**
- No centralized logging strategy
- Mix of `console.log`, `console.warn`, `console.error`, `forge-logger`, and `logger.js`
- Many logs fire in render loops or per-instance operations
- On pages with 50 Embeds, logs multiply by 50x
- Makes debugging impossible due to noise
- No way to disable logs in production

**Suggested Fix:**
1. Audit all console statements and categorize:
   - Debug logs (should use `logger.js` with namespaces)
   - Error logs (can stay as console.error)
   - Info logs (should use structured logger)
2. Replace all debug/info console.log with `logger.js` namespaced loggers
3. Add ESLint rule to prevent new console.log statements
4. Document logging strategy in README
5. Use `forge-logger.js` for backend operations, `logger.js` for frontend

**Rationale:**
- Centralized logging allows control and filtering
- Rate limiting prevents floods
- Namespaced logging allows selective enabling
- Makes debugging actually possible

**Effort Estimate:** Large (requires codebase-wide refactoring)

---

#### Finding 4.3.3: Debug Logs Left in Production Code

**Priority:** High
**Category:** Code Smell / Console Flooding
**Stage:** 4
**Phase:** 4.3
**File:** src/resolvers/excerpt-resolvers.js:22-30, 87-123

**Issue:** `saveExcerpt()` contains extensive DEBUG logging that should be removed or gated behind a debug flag.

**Current Code:**
```javascript
export async function saveExcerpt(req) {
  // DEBUG: Log the entire payload to see what we receive
  console.log('[saveExcerpt] RAW PAYLOAD:', JSON.stringify(req.payload, null, 2));
  console.log('[saveExcerpt] documentationLinks from payload:', req.payload.documentationLinks);
  console.log('[saveExcerpt] documentationLinks type:', typeof req.payload.documentationLinks);
  // ... 5 more DEBUG logs ...
  
  // DEBUG: Log what we're saving
  console.log('[saveExcerpt] About to save excerpt with documentationLinks:', excerpt.documentationLinks);
  console.log('[saveExcerpt] Full excerpt object before storage.set:', JSON.stringify(excerpt, null, 2));
  // ... more DEBUG logs ...
  
  // DEBUG: Immediately read it back to verify it was saved
  const verifyExcerpt = await storage.get(`excerpt:${id}`);
  console.log('[saveExcerpt] Verification - read back from storage:', { ... });
}
```

**Problem:**
- DEBUG logs should not be in production code
- Logs entire payload objects (potentially large)
- Fires on EVERY Source save operation
- Makes console unusable during normal operations
- Performance impact from JSON.stringify on large objects

**Suggested Fix:**
1. Remove all DEBUG console.log statements
2. If debugging is needed, use `logger.js` with `app:debug` namespace
3. Gate behind environment variable or localStorage flag
4. Use structured logging instead of raw console.log

**Rationale:**
- Production code should not have debug logs
- Debug logs should be opt-in, not always-on
- Structured logging is more maintainable

**Effort Estimate:** Small

---

### Phase 4.2: Business Logic Utilities - Staleness Detection

**Files Reviewed:**
- `src/utils/detection-utils.js`
- `src/utils/hash-utils.js`

---

#### Finding 4.2.1: Variable Detection Regex May Miss Edge Cases

**Priority:** High
**Category:** Edge Case Handling / False Positives
**Stage:** 4
**Phase:** 4.2
**File:** src/utils/detection-utils.js:28-58

**Issue:** `detectVariables()` uses regex `/\{\{([^}]+)\}\}/g` which may not handle all edge cases correctly (nested braces, escaped characters, malformed syntax).

**Current Code:**
```javascript
export function detectVariables(content) {
  const variableRegex = /\{\{([^}]+)\}\}/g;
  let match;
  
  while ((match = variableRegex.exec(textContent)) !== null) {
    const varName = match[1].trim();
    // Skip toggle markers
    if (varName.startsWith('toggle:') || varName.startsWith('/toggle:')) {
      continue;
    }
    // ...
  }
}
```

**Problem:**
- Regex `[^}]+` will match across multiple `}}` if there are nested braces
- Example: `{{var1}} {{var2}}` could match incorrectly if content has `}}` in it
- No handling for escaped braces or malformed syntax
- No validation that variable name is valid (could be empty string, whitespace-only, etc.)
- Could create false positives (detecting variables that aren't actually variables)

**Suggested Fix:**
1. Use more precise regex that handles edge cases:
   ```javascript
   const variableRegex = /\{\{([^{}]+)\}\}/g; // More restrictive
   ```
2. Add validation for variable names (non-empty, no special characters, etc.)
3. Add test cases for edge cases:
   - Nested braces: `{{var1}} {{var2}}`
   - Escaped braces: `\{var\}`
   - Malformed: `{{var` (missing closing)
   - Whitespace: `{{  var  }}`
4. Consider using a proper parser instead of regex for complex cases

**Rationale:**
- Regex-based parsing is fragile
- Edge cases can cause false positives/negatives
- Proper validation prevents data corruption

**Effort Estimate:** Medium

---

#### Finding 4.2.2: Hash Calculation May Have Timing/Consistency Issues

**Priority:** High
**Category:** Staleness Detection / False Positives
**Stage:** 4
**Phase:** 4.2
**File:** src/utils/hash-utils.js:59-80

**Issue:** `calculateContentHash()` normalizes JSON but doesn't handle all edge cases that could cause inconsistent hashing (undefined vs null, array ordering, etc.).

**Current Code:**
```javascript
export function calculateContentHash(excerpt) {
  const hashableContent = {
    content: excerpt.content,
    name: excerpt.name,
    category: excerpt.category,
    variables: excerpt.variables || [],
    toggles: excerpt.toggles || [],
    documentationLinks: excerpt.documentationLinks || []
  };
  
  const normalized = normalizeJSON(hashableContent);
  const jsonString = JSON.stringify(normalized);
  const hash = crypto.createHash('sha256').update(jsonString).digest('hex');
  return hash;
}
```

**Problem:**
- `normalizeJSON()` handles key sorting but may not handle:
  - `undefined` vs `null` (JSON.stringify converts undefined to omitted, null stays)
  - Array element ordering (arrays are not sorted, but should they be?)
  - Empty arrays vs undefined (both normalized to `[]`?)
  - Whitespace in strings (should be normalized?)
- If ADF content structure changes slightly (e.g., Confluence reorders keys), hash might change even if content is semantically identical
- No validation that hash calculation is deterministic across all code paths

**Suggested Fix:**
1. Add comprehensive test cases for hash consistency:
   - Same content with different key ordering
   - Same content with undefined vs null
   - Same content with empty arrays vs undefined
2. Document exactly what causes hash changes
3. Add hash calculation logging in debug mode to trace inconsistencies
4. Consider normalizing array element ordering if order doesn't matter semantically

**Rationale:**
- Hash inconsistencies cause false staleness detections
- User confusion when "Update Available" appears for unchanged content
- Need deterministic hashing across all scenarios

**Effort Estimate:** Medium

---

### Phase 4.1: ADF Manipulation - Edge Case Handling

**Files Reviewed:**
- `src/utils/adf-utils.js`

---

#### Finding 4.1.1: ADF Text Extraction Doesn't Handle All Node Types

**Priority:** High
**Category:** Edge Case Handling / Stability
**Stage:** 4
**Phase:** 4.1
**File:** src/utils/adf-utils.js:26-44

**Issue:** `extractTextFromAdf()` only handles text nodes and content arrays, but ADF has many node types (tables, code blocks, mentions, etc.) that may contain text in different structures.

**Current Code:**
```javascript
export function extractTextFromAdf(adfNode) {
  if (!adfNode) return '';
  
  let text = '';
  
  if (adfNode.text) {
    text += adfNode.text;
  }
  
  if (adfNode.content && Array.isArray(adfNode.content)) {
    for (const child of adfNode.content) {
      text += extractTextFromAdf(child);
    }
  }
  
  return text;
}
```

**Problem:**
- Doesn't handle table cells (text might be in `tableCell.content`)
- Doesn't handle code blocks (text might be in `codeBlock.content` or `attrs.language`)
- Doesn't handle mentions (text might be in `mention.attrs.text` or `mention.attrs.id`)
- Doesn't handle media (alt text in `media.attrs.alt`)
- Missing text from these node types could cause:
  - Variables/toggles not detected if they're in tables/code blocks
  - Incomplete text extraction for search/analysis
  - False negatives in content detection

**Suggested Fix:**
1. Add handling for all ADF node types that can contain text:
   - `tableCell`, `tableRow`, `tableHeader`
   - `codeBlock`, `inlineCode`
   - `mention`, `emoji`
   - `media` (alt text)
   - `expand`, `panel` (collapsible content)
2. Add test cases for each node type
3. Document which node types are supported
4. Add fallback for unknown node types (log warning, continue)

**Rationale:**
- Incomplete text extraction causes missed variables/toggles
- Users expect all content to be searchable
- Edge cases in ADF structure are common

**Effort Estimate:** Medium

---

#### Finding 4.1.2: ADF Traversal Has No Depth Limit or Cycle Detection

**Priority:** Critical
**Category:** Stability / Performance
**Stage:** 4
**Phase:** 4.1
**File:** src/utils/adf-utils.js:26-44, 60-91

**Issue:** Both `extractTextFromAdf()` and `findHeadingBeforeMacro()` recursively traverse ADF without depth limits or cycle detection. Malformed ADF with circular references could cause stack overflow.

**Current Code:**
```javascript
export function extractTextFromAdf(adfNode) {
  // ... no depth limit ...
  if (adfNode.content && Array.isArray(adfNode.content)) {
    for (const child of adfNode.content) {
      text += extractTextFromAdf(child); // Recursive, no depth check
    }
  }
}
```

**Problem:**
- No maximum depth limit (could recurse infinitely on malformed ADF)
- No cycle detection (circular references would cause infinite loop)
- Stack overflow risk on deeply nested or malformed ADF
- No error handling for malformed structure

**Suggested Fix:**
1. Add depth parameter with maximum limit (e.g., 100 levels)
2. Add cycle detection using Set to track visited nodes
3. Add error handling for stack overflow scenarios
4. Log warnings when depth limit is reached
5. Return partial results instead of crashing

**Rationale:**
- Prevents crashes on malformed ADF
- Graceful degradation is better than failure
- Protects against malicious or corrupted content

**Effort Estimate:** Small

---

## Stage 6: Workers & Async Processing Review

### Phase 6.2: Worker Helpers - Orphan Detection

**Files Reviewed:**
- `src/workers/helpers/page-scanner.js`
- `src/workers/helpers/orphan-detector.js`
- `src/workers/checkIncludesWorker.js`

---

#### Finding 6.2.1: Orphan Detection Has Extensive Logging That Will Flood Console

**Priority:** Critical
**Category:** Console Flooding / Performance
**Stage:** 6
**Phase:** 6.2
**File:** src/workers/helpers/page-scanner.js:56-138

**Issue:** `checkMacroExistsInADF()` logs extensively for every macro search, including logging every extension node found. During "Check All Embeds" operation, this generates thousands of log lines.

**Current Code:**
```javascript
export function checkMacroExistsInADF(node, targetLocalId, depth = 0) {
  if (depth === 0) {
    console.log(`[CHECK-MACRO] ðŸ” Searching for localId: ${targetLocalId}`);
  }
  
  if (node.type === 'extension') {
    // Log EVERY extension we find for debugging
    console.log(`[CHECK-MACRO] Found extension at depth ${depth}:`, {
      // ... full object logged
    });
  }
  // ... 7 more console.log statements ...
}
```

**Problem:**
- Logs fire for EVERY macro search (one per Embed)
- Logs EVERY extension node during recursive search
- During "Check All Embeds" with 200 Embeds, this could generate 2000+ log lines
- Makes console unusable
- Performance impact from object serialization

**Suggested Fix:**
1. Remove or gate all logging behind debug flag
2. Only log summary statistics (e.g., "Searched 50 pages, found 3 orphans")
3. Use structured logger with rate limiting
4. Log only on failure, not during search

**Rationale:**
- Debug logs should not flood production
- Summary logs are more useful than per-node logs
- Rate limiting prevents console spam

**Effort Estimate:** Small

---

#### Finding 6.2.2: Orphan Detection Search May Miss Macros in Edge Cases

**Priority:** Critical
**Category:** False Negatives / Data Safety
**Stage:** 6
**Phase:** 6.2
**File:** src/workers/helpers/page-scanner.js:56-138

**Issue:** `checkMacroExistsInADF()` searches for macros by `localId`, but the search may miss macros if:
1. `localId` is stored in a different location than expected
2. Extension key matching fails for some macro variants
3. ADF structure is nested in unexpected ways

**Current Code:**
```javascript
export function checkMacroExistsInADF(node, targetLocalId, depth = 0) {
  // Check if this node is an extension (macro)
  if (node.type === 'extension') {
    const extensionKey = node.attrs?.extensionKey || '';
    const isOurMacro = extensionKey.includes('blueprint-standard-embed') ||
                       extensionKey.includes('smart-excerpt-include') || // Legacy
                       extensionKey.includes('blueprint-standard-embed-poc') || // POC
                       extensionKey === 'blueprint-standard-embed' ||
                       extensionKey === 'smart-excerpt-include' ||
                       extensionKey === 'blueprint-standard-embed-poc';
    
    if (isOurMacro) {
      if (node.attrs?.localId === targetLocalId) {
        return true;
      }
    }
    
    // Also check if extensionType matches
    if (node.attrs?.extensionType === 'com.atlassian.confluence.macro.core' ||
        node.attrs?.extensionType === 'com.atlassian.ecosystem') {
      if (node.attrs?.localId === targetLocalId) {
        return true;
      }
    }
  }
  
  // Recursively check content array
  if (Array.isArray(node.content)) {
    for (const child of node.content) {
      if (checkMacroExistsInADF(child, targetLocalId, depth + 1)) {
        return true;
      }
    }
  }
  
  // Also check marks array
  if (Array.isArray(node.marks)) {
    for (const mark of node.marks) {
      if (checkMacroExistsInADF(mark, targetLocalId, depth + 1)) {
        return true;
      }
    }
  }
}
```

**Problem:**
- Only checks `node.attrs.localId` - what if `localId` is in `node.attrs.parameters.localId`?
- Extension key matching uses `includes()` which could match incorrectly
- Doesn't check `bodiedExtension` nodes (only `extension`)
- Marks array traversal may be unnecessary (marks don't typically contain macros)
- No validation that search is complete
- False negatives cause data deletion (CRITICAL)

**Suggested Fix:**
1. Check ALL possible locations for `localId`:
   - `node.attrs.localId`
   - `node.attrs.parameters.localId`
   - `node.attrs.parameters.macroParams.localId`
   - `node.attrs.parameters.macroParams.localId.value`
2. Also check `bodiedExtension` nodes (not just `extension`)
3. Add test cases for all ADF structure variations
4. Add logging (gated behind debug flag) showing search path
5. Consider using ADF schema validation to ensure structure is correct

**Rationale:**
- False negatives cause data deletion - this is CRITICAL
- Need to handle all possible ADF structure variations
- Comprehensive search prevents false positives

**Effort Estimate:** Medium

---

#### Finding 6.2.3: Orphan Detection Doesn't Handle Page Fetch Failures Gracefully

**Priority:** High
**Category:** False Positives / Data Safety
**Stage:** 6
**Phase:** 6.2
**File:** src/workers/checkIncludesWorker.js:168-214

**Issue:** If page fetch fails (network error, permission denied, etc.), all Embeds on that page are marked as orphaned, even though they may still exist.

**Current Code:**
```javascript
const pageResult = await fetchPageContent(pageId);

if (!pageResult.success) {
  // Page doesn't exist or is inaccessible
  console.log(`[WORKER] ${pageResult.error}`);
  
  const orphaned = await handlePageNotFound(pageIncludes, pageResult.error, dryRun);
  orphanedIncludes.push(...orphaned);
}
```

**Problem:**
- Network errors are treated the same as "page deleted"
- Permission errors are treated the same as "page deleted"
- Temporary API failures cause false positives
- All Embeds on page are marked orphaned even if only fetch failed
- No retry logic for transient failures
- No distinction between "page deleted" vs "fetch failed"

**Suggested Fix:**
1. Distinguish between error types:
   - HTTP 404 = page deleted (legitimate orphan)
   - HTTP 403 = permission denied (may be temporary, don't mark orphaned)
   - HTTP 500/network error = transient failure (retry, don't mark orphaned)
2. Add retry logic for transient failures (3 retries with exponential backoff)
3. Only mark as orphaned if page is confirmed deleted (404) or fetch fails after retries
4. Log error type separately from orphaned status
5. Add "fetch failed" status separate from "orphaned" status

**Rationale:**
- Prevents false positives from transient failures
- Network errors shouldn't cause data deletion
- Retry logic handles temporary API issues

**Effort Estimate:** Medium

---

## Stage 2: Resolver Layer Review

### Phase 2.1: Core Resolvers (CRUD Operations)

**Files Reviewed:**
- `src/resolvers/excerpt-resolvers.js`
- `src/resolvers/include-resolvers.js`
- `src/resolvers/simple-resolvers.js`
- `src/resolvers/usage-resolvers.js`

---

#### Finding 2.1.1: Inconsistent Return Value Contracts Across Resolvers

**Priority:** High
**Category:** API Contracts / Consistency
**Stage:** 2
**Phase:** 2.1
**File:** src/resolvers/*.js (multiple files)

**Issue:** Resolvers have inconsistent return value structures. Some return `{ success: true, data }`, others return `{ success: true, excerpt }`, others return data directly, and some throw errors instead of returning error objects.

**Current Code Examples:**
```javascript
// excerpt-resolvers.js - returns data directly (no success wrapper)
return {
  excerptId: id,
  excerptName: excerptName,
  // ... data fields
};

// simple-resolvers.js - returns { success, excerpt }
return {
  success: true,
  excerpt: excerpt
};

// include-resolvers.js - returns { success: true } (no data)
return {
  success: true
};

// Some resolvers throw errors, others return { success: false, error }
```

**Problem:**
- Frontend code must handle multiple response formats
- No consistent error handling pattern
- Makes it hard to write generic error handling
- Type safety is impossible without consistent contracts
- Some resolvers return partial data on error, others return nothing

**Suggested Fix:**
1. Standardize all resolver return values to:
   ```javascript
   // Success case
   { success: true, data: {...} }
   
   // Error case
   { success: false, error: "error message", errorCode?: "ERROR_CODE" }
   ```
2. Never throw errors from resolvers (always return error objects)
3. Document the standard contract in a resolver template/guide
4. Add TypeScript types or JSDoc types for all resolver return values

**Rationale:**
- Consistent contracts make frontend code simpler
- Error handling is predictable
- Type safety becomes possible
- Easier to test and maintain

**Effort Estimate:** Large (requires refactoring all resolvers)

---

#### Finding 2.1.2: Missing Input Validation in Resolver Functions

**Priority:** High
**Category:** Security / Data Integrity
**Stage:** 2
**Phase:** 2.1
**File:** src/resolvers/excerpt-resolvers.js:21-138

**Issue:** `saveExcerpt()` accepts payload without validating required fields or data types. Missing or invalid data could cause storage corruption.

**Current Code:**
```javascript
export async function saveExcerpt(req) {
  const { excerptName, category, content, excerptId, variableMetadata, toggleMetadata, documentationLinks, sourcePageId, sourcePageTitle, sourceSpaceKey, sourceLocalId } = req.payload;
  
  // No validation that excerptName is a string
  // No validation that content is valid ADF
  // No validation that excerptId is valid UUID format
  // No validation that documentationLinks is an array
  
  const id = excerptId || generateUUID();
  // ... proceeds with potentially invalid data
}
```

**Problem:**
- Invalid data types could cause runtime errors
- Missing required fields could create incomplete records
- Malformed ADF could corrupt storage
- No validation means bugs are discovered late (at runtime)
- Security risk if malicious data is accepted

**Suggested Fix:**
1. Add input validation at the start of each resolver:
   ```javascript
   if (!excerptName || typeof excerptName !== 'string') {
     return { success: false, error: 'excerptName is required and must be a string' };
   }
   if (content && typeof content !== 'object') {
     return { success: false, error: 'content must be an ADF object' };
   }
   ```
2. Use `validateExcerptData()` before saving
3. Create a validation utility for common patterns
4. Add JSDoc documenting required/optional parameters

**Rationale:**
- Prevents data corruption
- Fails fast with clear error messages
- Security best practice (input validation)
- Makes debugging easier

**Effort Estimate:** Medium

---

#### Finding 2.1.3: saveExcerpt Has Extensive DEBUG Logging in Production

**Priority:** High
**Category:** Console Flooding
**Stage:** 2
**Phase:** 2.1
**File:** src/resolvers/excerpt-resolvers.js:22-30, 87-123

**Issue:** `saveExcerpt()` contains 10+ DEBUG console.log statements that log entire payloads and objects. These fire on every Source save operation.

**Current Code:**
```javascript
export async function saveExcerpt(req) {
  // DEBUG: Log the entire payload to see what we receive
  console.log('[saveExcerpt] RAW PAYLOAD:', JSON.stringify(req.payload, null, 2));
  console.log('[saveExcerpt] documentationLinks from payload:', req.payload.documentationLinks);
  // ... 8 more DEBUG logs ...
  
  // DEBUG: Immediately read it back to verify it was saved
  const verifyExcerpt = await storage.get(`excerpt:${id}`);
  console.log('[saveExcerpt] Verification - read back from storage:', { ... });
}
```

**Problem:**
- DEBUG logs should not be in production code
- Logs entire payload objects (potentially large, contains sensitive data?)
- Fires on EVERY Source save operation
- Makes console unusable during normal operations
- Performance impact from JSON.stringify on large objects
- Security risk if payloads contain sensitive data

**Suggested Fix:**
1. Remove all DEBUG console.log statements
2. If debugging is needed, use `logger.js` with `app:debug` namespace
3. Gate behind environment variable or localStorage flag
4. Use structured logging instead of raw console.log
5. Never log entire payloads (log only relevant fields)

**Rationale:**
- Production code should not have debug logs
- Debug logs should be opt-in, not always-on
- Structured logging is more maintainable
- Prevents sensitive data leakage

**Effort Estimate:** Small

---

#### Finding 2.1.4: saveVariableValues Has Complex Auto-Transition Logic Without Tests

**Priority:** Medium
**Category:** Business Logic / Testing
**Stage:** 2
**Phase:** 2.1
**File:** src/resolvers/include-resolvers.js:72-109

**Issue:** `saveVariableValues()` contains complex auto-transition logic that changes redline status from "approved" to "needs-revision" when content changes. This logic queries version system and compares hashes, but there's no indication of test coverage.

**Current Code:**
```javascript
// AUTO-TRANSITION LOGIC: Check if approved Embed content has changed
if (existingConfig && existingConfig.redlineStatus === 'approved' && existingConfig.approvedContentHash) {
  const versionsResult = await listVersions(storage, localId);
  
  if (versionsResult.success && versionsResult.versions.length > 0) {
    const latestVersion = versionsResult.versions[0];
    const currentContentHash = latestVersion.contentHash;
    
    if (currentContentHash !== existingConfig.approvedContentHash) {
      // Auto-transition status to "needs-revision"
      // ... complex logic ...
    }
  }
}
```

**Problem:**
- Complex business logic without visible test coverage
- Multiple async operations (listVersions, hash comparison)
- Edge cases not obvious (what if versionsResult fails? what if no versions?)
- Logic is buried in save function (hard to test in isolation)
- No documentation of when auto-transition should/shouldn't happen

**Suggested Fix:**
1. Extract auto-transition logic to separate function for testability
2. Add comprehensive test cases:
   - Approved Embed with unchanged content (should stay approved)
   - Approved Embed with changed content (should transition)
   - Approved Embed with version system failure (should handle gracefully)
   - Approved Embed with no versions (edge case)
3. Add JSDoc documenting the auto-transition behavior
4. Add logging (structured) when auto-transition occurs

**Rationale:**
- Complex business logic needs tests
- Isolated functions are easier to test
- Edge cases need explicit handling
- Documentation helps future maintainers

**Effort Estimate:** Medium

---

### Phase 2.2: Specialized Resolvers

**Files Reviewed:**
- `src/resolvers/verification-resolvers.js`
- `src/resolvers/version-resolvers.js`
- `src/resolvers/redline-resolvers.js`

---

#### Finding 2.2.1: checkAllSources Has Extensive Console Logging

**Priority:** High
**Category:** Console Flooding
**Stage:** 2
**Phase:** 2.2
**File:** src/resolvers/verification-resolvers.js:85-478

**Issue:** `checkAllSources()` contains 20+ console.log/error statements that fire during the checking process. This operation can process many Sources, generating hundreds of log lines.

**Current Code:**
```javascript
export async function checkAllSources(req) {
  console.log('ðŸ” ACTIVE CHECK: Checking all Sources against their pages...');
  console.log('Total excerpts to check:', excerptIndex.excerpts.length);
  console.log(`âš ï¸ Excerpt "${excerpt.name}" missing sourcePageId or sourceLocalId, skipping`);
  console.log(`Grouped excerpts into ${excerptsByPage.size} pages to check`);
  // ... 15+ more console.log statements ...
}
```

**Problem:**
- Logs fire for every Source checked
- During "Check All Sources" with 100 Sources, generates 100+ log lines
- Mix of console.log and console.error makes filtering difficult
- No structured logging (can't filter by operation type)
- Makes console unusable during verification operations

**Suggested Fix:**
1. Replace console.log with structured logger (`logger.verification()`)
2. Log summary statistics instead of per-Source details
3. Only log errors and warnings, not info messages
4. Use progress tracking storage instead of console for status updates
5. Gate detailed logging behind debug flag

**Rationale:**
- Verification operations should be quiet unless there are errors
- Summary logs are more useful than per-item logs
- Structured logging allows filtering
- Progress tracking is better than console spam

**Effort Estimate:** Small

---

#### Finding 2.2.2: getRedlineQueue Fetches All Embed Configs Without Pagination

**Priority:** Medium
**Category:** Performance / Scalability
**Stage:** 2
**Phase:** 2.2
**File:** src/resolvers/redline-resolvers.js:45-199

**Issue:** `getRedlineQueue()` fetches ALL `macro-vars:*` keys from storage, then loads all Embed configs, then fetches page data for each. On spaces with 1000+ Embeds, this could be slow and hit API rate limits.

**Current Code:**
```javascript
export async function getRedlineQueue(req) {
  // Get all macro-vars:* keys (paginated, but still loads ALL)
  let allKeys = [];
  let cursor = undefined;
  
  do {
    const batch = await storage.query()
      .where('key', startsWith('macro-vars:'))
      .limit(100)
      .cursor(cursor)
      .getMany();
    
    allKeys = allKeys.concat(batch.results);
    cursor = batch.nextCursor;
  } while (cursor);
  
  // Load all Embed configs
  const embedConfigs = await Promise.all(
    allKeys.map(async (item) => {
      // ... fetch excerpt data ...
      // ... fetch page data via API ...
    })
  );
}
```

**Problem:**
- Loads ALL Embeds even if only showing first 20 in UI
- Fetches page data via API for ALL Embeds (could be 1000+ API calls)
- No pagination in the resolver (UI must handle all data)
- Could hit Confluence API rate limits
- Slow response time for large spaces
- Memory usage scales with total Embed count

**Suggested Fix:**
1. Add pagination parameters to resolver (limit, offset)
2. Only fetch page data for Embeds that will be displayed
3. Cache page data to avoid repeated API calls
4. Return total count separately from paginated results
5. Consider server-side filtering before fetching page data

**Rationale:**
- Pagination is essential for scalability
- Fetching data for 1000 Embeds when showing 20 is wasteful
- API rate limits are a real concern
- Faster response times improve UX

**Effort Estimate:** Medium

---

#### Finding 2.2.3: getConfluenceUser Returns Fallback Data Instead of Error

**Priority:** Low
**Category:** Error Handling / API Contracts
**Stage:** 2
**Phase:** 2.2
**File:** src/resolvers/redline-resolvers.js:425-481

**Issue:** `getConfluenceUser()` catches errors and returns fallback data with `error` field instead of returning `{ success: false }`. This makes error handling inconsistent.

**Current Code:**
```javascript
export async function getConfluenceUser(req) {
  try {
    const response = await api.asApp().requestConfluence(...);
    // ... return user data ...
  } catch (error) {
    console.error('[getConfluenceUser] Error:', error);
    // Return fallback data instead of throwing
    return {
      accountId,
      displayName: 'Unknown User',
      // ... fallback data ...
      error: error.message  // Error field in success response
    };
  }
}
```

**Problem:**
- Inconsistent with other resolvers (should return `{ success: false }`)
- Frontend must check for `error` field in what looks like success data
- Fallback data might mask real errors
- Makes error handling unpredictable

**Suggested Fix:**
1. Return consistent error format:
   ```javascript
   return {
     success: false,
     error: error.message,
     fallbackData: { ... }  // Optional fallback if needed
   };
   ```
2. Or return success with explicit `isFallback: true` flag
3. Document the fallback behavior in JSDoc
4. Consider if fallback is necessary (maybe UI should handle missing user data)

**Rationale:**
- Consistent error handling makes frontend code simpler
- Explicit fallback flags make behavior clear
- Error handling should be predictable

**Effort Estimate:** Small

---

## Stage 3: React Components Review

### Phase 3.1: Core UI Components

**Files Reviewed:**
- `src/EmbedContainer.jsx`
- `src/source-config.jsx`
- `src/source-display.jsx`

---

#### Finding 3.1.1: EmbedContainer Has 22 useState Hooks - Excessive State Management

**Priority:** Medium
**Category:** Code Smell / Architecture
**Stage:** 3
**Phase:** 3.1
**File:** src/EmbedContainer.jsx:152-180

**Issue:** `EmbedContainer.jsx` uses 22 `useState` hooks, indicating complex state management that could benefit from consolidation or state management library.

**Current Code:**
```javascript
const [selectedExcerptId, setSelectedExcerptId] = useState(null);
const [isInitializing, setIsInitializing] = useState(true);
const [content, setContent] = useState(null);
const [excerptForViewMode, setExcerptForViewMode] = useState(null);
const [variableValues, setVariableValues] = useState(config?.variableValues || {});
const [toggleStates, setToggleStates] = useState(config?.toggleStates || {});
const [customInsertions, setCustomInsertions] = useState(config?.customInsertions || []);
const [internalNotes, setInternalNotes] = useState(config?.internalNotes || []);
// ... 14 more useState hooks ...
```

**Problem:**
- 22 separate state variables are hard to manage and reason about
- State updates can cause cascading re-renders
- Difficult to track which state changes trigger which effects
- Some state might be derivable from other state (redundancy)
- Makes component harder to test (many state combinations)

**Suggested Fix:**
1. Group related state into objects:
   ```javascript
   const [embedConfig, setEmbedConfig] = useState({
     variableValues: {},
     toggleStates: {},
     customInsertions: [],
     internalNotes: []
   });
   ```
2. Use `useReducer` for complex state logic
3. Consider if some state can be derived from props/context
4. Extract state management to custom hooks
5. Document state dependencies and update patterns

**Rationale:**
- Fewer state variables are easier to manage
- Grouped state reduces re-render cascades
- `useReducer` is better for complex state logic
- Custom hooks improve testability

**Effort Estimate:** Large (requires refactoring component)

---

#### Finding 3.1.2: source-config.jsx Has Console Logs in useEffect That Fire on Every State Change

**Priority:** High
**Category:** Console Flooding
**Stage:** 3
**Phase:** 3.1
**File:** src/source-config.jsx:172-174, 232-263

**Issue:** `source-config.jsx` has `useEffect` hooks with console.log statements that fire whenever state changes. This component is used for every Source macro, so logs multiply.

**Current Code:**
```javascript
// DEBUG: Log when excerptName state changes
useEffect(() => {
  console.log('[source-config] excerptName state changed to:', excerptName);
}, [excerptName]);

// DEBUG: Log what we received
console.log('[source-config] Loading excerpt data:', {
  excerptId,
  hasExcerptData: !!excerptData,
  // ... full object logged
});
```

**Problem:**
- Logs fire on EVERY state change (every keystroke in name field)
- Logs fire for EVERY Source macro on a page
- On a Source library page with 50 Sources, this generates hundreds of log lines
- Makes console unusable during normal editing
- Performance impact from object serialization

**Suggested Fix:**
1. Remove all DEBUG console.log statements
2. If debugging is needed, use `logger.js` with `app:debug` namespace
3. Gate behind localStorage debug flag
4. Only log errors, not state changes
5. Use React DevTools for state inspection instead of console logs

**Rationale:**
- Debug logs should not fire in production
- State change logging is what React DevTools is for
- Console should be clean during normal operations

**Effort Estimate:** Small

---

#### Finding 3.1.3: StableTextfield Has Console Logs That Fire on Value Updates

**Priority:** Medium
**Category:** Console Flooding
**Stage:** 3
**Phase:** 3.4
**File:** src/components/common/StableTextfield.jsx:72, 90

**Issue:** `StableTextfield` component logs to console on every value update. This component is used extensively throughout the app, so logs multiply.

**Current Code:**
```javascript
if (currentValue !== newValue) {
  console.log('[StableTextfield] Updating value from', currentValue, 'to', newValue);
  // ... update logic ...
  
  setTimeout(() => {
    if (textFieldRef.current && textFieldRef.current.value !== newValue) {
      console.log('[StableTextfield] Retrying value update to', newValue);
      // ... retry logic ...
    }
  }, 10);
}
```

**Problem:**
- Logs fire on EVERY text field update
- Used in forms with many fields (Variables tab, Custom Insertions, etc.)
- On a form with 10 fields, every keystroke generates 10+ log lines
- Makes console unusable during form editing
- Performance impact from string concatenation

**Suggested Fix:**
1. Remove console.log statements (this is a utility component, not a debug tool)
2. If debugging cursor issues is needed, use `logger.js` with `app:debug` namespace
3. Gate behind debug flag
4. Only log errors, not normal operations

**Rationale:**
- Utility components should be silent
- Debug logs should be opt-in
- Console should be clean during normal use

**Effort Estimate:** Small

---

## Stage 5: Hooks & State Management Review

### Phase 5.1: React Query Hooks

**Files Reviewed:**
- `src/hooks/embed-hooks.js`
- `src/hooks/admin-hooks.js`
- `src/hooks/redline-hooks.js`

---

#### Finding 5.1.1: React Query Hooks May Have Inconsistent Query Key Patterns

**Priority:** Medium
**Category:** Consistency / Cache Management
**Stage:** 5
**Phase:** 5.1
**File:** src/hooks/embed-hooks.js, src/hooks/admin-hooks.js

**Issue:** Need to verify that all React Query hooks use consistent query key patterns for proper cache invalidation and deduplication.

**Current Code:**
```javascript
// Need to verify patterns like:
queryKey: ['excerpt', excerptId]
queryKey: ['variableValues', localId]
queryKey: ['cachedContent', localId, excerptId]
```

**Problem:**
- Inconsistent query keys cause cache misses
- Cache invalidation might not work correctly
- Duplicate queries might not be deduplicated
- Hard to verify without reviewing all hooks

**Suggested Fix:**
1. Audit all query keys and document the pattern
2. Create a query key factory utility:
   ```javascript
   export const queryKeys = {
     excerpt: (id) => ['excerpt', id],
     variableValues: (localId) => ['variableValues', localId],
     // ... etc
   };
   ```
3. Use factory consistently across all hooks
4. Document query key structure in README

**Rationale:**
- Consistent query keys ensure proper caching
- Factory pattern prevents typos
- Documentation helps maintainers

**Effort Estimate:** Small

---

## Cross-Cutting Analysis

### Pattern Recognition Findings

---

#### Finding X.1: Inconsistent Error Handling Patterns

**Priority:** High
**Category:** Consistency / Error Handling
**Stage:** Cross-Cutting
**Phase:** All

**Issue:** Error handling is inconsistent across the codebase:
- Some functions throw errors
- Some return `{ success: false, error }`
- Some return `{ success: false }` with no error message
- Some log errors and return undefined
- Some catch and swallow errors silently

**Problem:**
- Frontend code must handle multiple error formats
- Some errors are lost (swallowed)
- Debugging is difficult when errors are inconsistent
- No standard error codes or types

**Suggested Fix:**
1. Standardize error handling:
   - Resolvers: Always return `{ success: false, error: string, errorCode?: string }`
   - Utilities: Throw errors (let resolvers catch and format)
   - Components: Catch errors, show user-friendly messages
2. Create error code constants
3. Document error handling patterns
4. Add error boundary components for React

**Rationale:**
- Consistent error handling makes code predictable
- Error codes enable programmatic handling
- User-friendly messages improve UX

**Effort Estimate:** Large (requires refactoring across codebase)

---

#### Finding X.2: Missing JSDoc on Many Exported Functions

**Priority:** Medium
**Category:** Documentation
**Stage:** Cross-Cutting
**Phase:** All

**Issue:** Many exported functions lack JSDoc comments documenting parameters, return values, and behavior. This makes the codebase harder to understand for new developers.

**Problem:**
- Function signatures don't explain what parameters mean
- Return value contracts are unclear
- Edge cases and side effects are undocumented
- Makes onboarding difficult
- IDE autocomplete is less helpful

**Suggested Fix:**
1. Add JSDoc to all exported functions:
   ```javascript
   /**
    * Save variable values for an Embed instance
    * @param {Object} req - Forge request object
    * @param {string} req.payload.localId - Embed macro localId
    * @param {string} req.payload.excerptId - Source excerpt ID
    * @param {Object} req.payload.variableValues - Variable values object
    * @returns {Promise<Object>} { success: boolean, error?: string }
    */
   ```
2. Document edge cases and side effects
3. Add @throws for functions that throw
4. Use TypeScript or JSDoc types for better IDE support

**Rationale:**
- Documentation helps new developers
- IDE autocomplete is more helpful
- Reduces need to read implementation to understand usage

**Effort Estimate:** Medium

---

## Summary Statistics - All Stages

**Total Files Reviewed:** 25+
**Total Findings:** 32
**Critical:** 3
**High:** 13
**Medium:** 14
**Low:** 2

**Critical Areas Identified:**
1. Console flooding (949 console statements, extensive logging in orphan detection, React components)
2. Orphan detection false positives/negatives (data safety issue)
3. Staleness detection edge cases (false positives cause user confusion)
4. Inconsistent API contracts across resolvers (makes frontend code complex)
5. Missing input validation (security/data integrity risk)
6. Excessive state management in EmbedContainer (22 useState hooks)
7. Inconsistent error handling patterns

**Recommendations:**
1. **Immediate:** Remove/gate debug logs in production code (all files)
2. **High Priority:** Fix orphan detection to handle all ADF structure variations
3. **High Priority:** Implement centralized logging strategy with rate limiting
4. **High Priority:** Standardize resolver return value contracts
5. **High Priority:** Add input validation to all resolvers
6. **High Priority:** Consolidate state management in EmbedContainer
7. **High Priority:** Standardize error handling patterns
8. **Medium Priority:** Add comprehensive test cases for edge cases
9. **Medium Priority:** Document all critical operations with sequence diagrams
10. **Medium Priority:** Add pagination to resolvers that fetch large datasets
11. **Medium Priority:** Add JSDoc to all exported functions

**Files Requiring Immediate Attention:**
- `src/resolvers/excerpt-resolvers.js` (remove DEBUG logs)
- `src/resolvers/verification-resolvers.js` (remove console.log statements)
- `src/workers/helpers/page-scanner.js` (gate/remove extensive logging)
- `src/source-config.jsx` (remove useEffect console.log)
- `src/components/common/StableTextfield.jsx` (remove console.log)
- `src/EmbedContainer.jsx` (consider state consolidation)

---

